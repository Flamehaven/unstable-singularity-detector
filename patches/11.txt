좋아요. 앞서 드린 패치들(재현·로깅·체크포인트·CI·문서)에 **더해도 “반드시” 필요한 최소 필수 패치**를 한 번에 넣을 수 있게 **실제 diff 형태로** 준비했습니다. 목표는 **수치 안정성·정밀도·설정 검증·경계조건 일관성**을 보장하는 것입니다.

---

# 필수 패치 1 — 정밀도/장치 제어(AMP 차단, float64 지원), 결정적 알고리즘

```diff
*** Begin Patch
*** Add File: src/usd/nn/precision.py
+import torch
+from dataclasses import dataclass
+
+@dataclass
+class PrecisionConfig:
+    dtype: str = "float64"  # "float32" | "float64"
+    device: str = "cuda"    # "cuda" | "cpu"
+
+def select_dtype(dtype: str):
+    if dtype == "float64":
+        return torch.float64
+    if dtype == "float32":
+        return torch.float32
+    raise ValueError(f"unsupported dtype: {dtype}")
+
+def setup_precision(cfg: PrecisionConfig):
+    dt = select_dtype(cfg.dtype)
+    torch.set_default_dtype(torch.float64 if dt == torch.float64 else torch.float32)
+    # AMP는 고정밀 탐색과 상충 → 기본 비활성화
+    torch.backends.cuda.matmul.allow_tf32 = False
+    torch.backends.cudnn.allow_tf32 = False
+    # 결정적 알고리즘(가능한 한)
+    torch.use_deterministic_algorithms(True, warn_only=True)
+    return dt, torch.device(cfg.device if torch.cuda.is_available() and cfg.device == "cuda" else "cpu")
*** End Patch
```

```diff
*** Begin Patch
*** Update File: configs/base.yaml
@@
 train:
   max_steps: 20000
   log_interval: 50
   seed: 2025
   log_tb: true
   log_dir: runs/exp1
   ckpt_interval: 200
   ckpt_last: artifacts/exp1/last.ckpt
   ckpt_best: artifacts/exp1/best.ckpt
   resume: true
+precision:
+  dtype: float64   # float32|float64 (권장: float64)
+  device: cuda     # cuda|cpu
*** End Patch
```

```diff
*** Begin Patch
*** Update File: src/usd/train.py
@@
-from usd.solver import GaussNewtonSolver
+from usd.solver import GaussNewtonSolver
 from usd.metrics import pde_residual_stats
 from usd.utils.repro import set_global_seed
 from torch.utils.tensorboard import SummaryWriter
+from usd.nn.precision import setup_precision, PrecisionConfig
+import torch, os
@@
 def main(cfg):
     set_global_seed(cfg.train.seed, deterministic=True)
+    # precision & device
+    dt, dev = setup_precision(PrecisionConfig(**cfg["train"]["precision"]))
     writer = SummaryWriter(log_dir=cfg.train.log_dir) if cfg.train.log_tb else None
-    solver = GaussNewtonSolver(cfg)
+    solver = GaussNewtonSolver(cfg, device=dev, default_dtype=dt)
@@
     if writer: writer.close()
*** End Patch
```

---

# 필수 패치 2 — 설정 스키마 검증(Pydantic) + 안전한 로더

```diff
*** Begin Patch
*** Add File: src/usd/config.py
+from pydantic import BaseModel, Field, ValidationError, Extra
+from typing import Optional
+import yaml
+
+class Precision(BaseModel, extra=Extra.forbid):
+    dtype: str = Field(pattern="^(float32|float64)$")
+    device: str = Field(pattern="^(cpu|cuda)$")
+
+class Train(BaseModel, extra=Extra.forbid):
+    max_steps: int = Field(ge=1)
+    log_interval: int = Field(ge=1)
+    seed: int
+    log_tb: bool = True
+    log_dir: str
+    ckpt_interval: int = Field(ge=1)
+    ckpt_last: str
+    ckpt_best: str
+    resume: bool = True
+    precision: Precision
+
+class Config(BaseModel, extra=Extra.forbid):
+    train: Train
+
+def load_config(path: str) -> Config:
+    with open(path, "r", encoding="utf-8") as f:
+        raw = yaml.safe_load(f)
+    try:
+        return Config(**raw)
+    except ValidationError as e:
+        raise SystemExit(f"[ConfigError]\n{e}")
*** End Patch
```

```diff
*** Begin Patch
*** Update File: src/usd/train.py
@@
-from usd.solver import GaussNewtonSolver
+from usd.solver import GaussNewtonSolver
 from usd.metrics import pde_residual_stats
 from usd.utils.repro import set_global_seed
 from torch.utils.tensorboard import SummaryWriter
 from usd.nn.precision import setup_precision, PrecisionConfig
+from usd.config import load_config
@@
-def main(cfg):
+def main(cfg):
@@
 
-if __name__ == "__main__":
-    import argparse, yaml
-    ap = argparse.ArgumentParser()
-    ap.add_argument("--config", required=True)
-    args = ap.parse_args()
-    with open(args.config, "r") as f:
-        cfg = yaml.safe_load(f)
-    main(cfg)
+if __name__ == "__main__":
+    import argparse
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--config", required=True)
+    args = ap.parse_args()
+    cfg = load_config(args.config).dict()
+    main(cfg)
*** End Patch
```

---

# 필수 패치 3 — NaN/Inf 가드, 잔차 악화 방지용 라인서치/댐핑(Gauss–Newton)

```diff
*** Begin Patch
*** Add File: src/usd/utils/checks.py
+import torch
+
+def assert_finite(x: torch.Tensor, name: str):
+    if not torch.isfinite(x).all():
+        bad = (~torch.isfinite(x)).sum().item()
+        raise FloatingPointError(f"{name} contains non-finite values (count={bad})")
*** End Patch
```

```diff
*** Begin Patch
*** Update File: src/usd/solver.py
@@
-from dataclasses import dataclass
+from dataclasses import dataclass
+import torch
+from usd.utils.checks import assert_finite
+from usd.metrics import pde_residual_stats
@@
-@dataclass
-class GaussNewtonSolver:
-    ...
+@dataclass
+class GaussNewtonSolver:
+    # 기존 필드 생략…
+    device: torch.device = None
+    default_dtype: torch.dtype = torch.float64
@@
-    def step(self):
-        # 기존 Gauss-Newton 한 스텝
-        loss, residual, scalings = self._forward()
-        update = self._solve_gn(residual)  # Δθ
-        self._apply(update)
-        return loss, residual, scalings
+    def step(self):
+        # Forward
+        loss, residual, scalings = self._forward()
+        assert_finite(loss, "loss")
+        assert_finite(residual, "residual")
+
+        # Solve (GN)
+        update = self._solve_gn(residual)  # Δθ
+        assert_finite(update, "gn_update")
+
+        # Backtracking line-search with Levenberg–Marquardt damping
+        base_stats = pde_residual_stats(residual)
+        base_obj = float(loss.detach().cpu().item())
+        lm = self.cfg.get("solver", {}).get("lm_damping", 1e-3)
+        shrink = self.cfg.get("solver", {}).get("ls_shrink", 0.5)
+        min_step = self.cfg.get("solver", {}).get("ls_min_step", 1e-6)
+        step = 1.0
+        best = (base_obj, None, base_stats)
+
+        for _ in range(20):
+            self._apply(update, step=step, damping=lm)
+            new_loss, new_residual, _ = self._forward()
+            if torch.isfinite(new_loss).all():
+                new_obj = float(new_loss.detach().cpu().item())
+                if new_obj <= base_obj:  # sufficient decrease (간단 기준)
+                    best = (new_obj, step, pde_residual_stats(new_residual))
+                    break
+            # rollback & shrink
+            self._apply(update, step=-step, damping=lm)  # revert tentative
+            step *= shrink
+            if step < min_step:
+                break
+
+        # 최종 적용(이미 적용된 상태면 스킵)
+        if best[1] is None:
+            # 마지막 안정적 소폭 업데이트만 적용
+            self._apply(update, step=min_step, damping=lm)
+
+        return loss, residual, scalings
@@
-    def _apply(self, update):
-        # 파라미터 갱신
-        for p, u in zip(self.model.parameters(), update):
-            p.data.add_(u)
+    def _apply(self, update, step: float = 1.0, damping: float = 0.0):
+        """θ ← θ + step * ( (I * -damping) ⊙ Δθ )"""
+        scale = 1.0 / (1.0 + damping) if damping > 0 else 1.0
+        for p, u in zip(self.model.parameters(), update):
+            p.data.add_(u, alpha=step * scale)
*** End Patch
```

```diff
*** Begin Patch
*** Update File: configs/base.yaml
@@
+solver:
+  lm_damping: 1.0e-3
+  ls_shrink: 0.5
+  ls_min_step: 1.0e-6
*** End Patch
```

---

# 필수 패치 4 — 경계조건/자기유사 좌표 변환의 “단위·일관성” 체크

```diff
*** Begin Patch
*** Add File: src/usd/physics/bc.py
+import torch
+from typing import Literal
+
+def enforce_bc(u: torch.Tensor, bc: torch.Tensor, mode: Literal["dirichlet","neumann"]="dirichlet"):
+    """
+    u: [..., C, *grid]   추정 필드
+    bc: [..., C, *grid]  경계 마스크 또는 값
+    """
+    if mode == "dirichlet":
+        # 경계 값 덮어쓰기 (bc가 값 텐서라는 가정)
+        u = u.clone()
+        u[..., :] = torch.where(torch.isfinite(bc), bc, u)
+        return u
+    elif mode == "neumann":
+        # TODO: 그라디언트 기반 경계 적용(단순 마스크 자리표시자)
+        return u
+    else:
+        raise ValueError(mode)
*** End Patch
```

```diff
*** Begin Patch
*** Add File: src/usd/physics/self_similar.py
+import torch
+from dataclasses import dataclass
+
+@dataclass
+class Similarity:
+    # x' = x / (T - t)^alpha,  u' = (T - t)^beta u
+    alpha: float
+    beta: float
+
+def forward_transform(x: torch.Tensor, t: torch.Tensor, sim: Similarity):
+    tau = torch.clamp_min(1.0 - t, 1e-12)
+    return x / (tau ** sim.alpha)
+
+def inverse_transform(xp: torch.Tensor, t: torch.Tensor, sim: Similarity):
+    tau = torch.clamp_min(1.0 - t, 1e-12)
+    return xp * (tau ** sim.alpha)
*** End Patch
```

---

# 필수 패치 5 — 핵심 테스트(정밀도/결정성/NaN 가드/라인서치/BC)

```diff
*** Begin Patch
*** Add File: tests/test_precision_and_determinism.py
+import torch
+from usd.nn.precision import setup_precision, PrecisionConfig
+
+def test_precision_float64_cpu():
+    dt, dev = setup_precision(PrecisionConfig(dtype="float64", device="cpu"))
+    a = torch.ones(3, dtype=dt, device=dev)
+    assert a.dtype == torch.float64
+
+def test_determinism_flag():
+    # 경고만 발생 가능, 설정 자체가 실행돼야 함
+    setup_precision(PrecisionConfig())
+    assert torch.is_deterministic()
*** End Patch
```

```diff
*** Begin Patch
*** Add File: tests/test_nan_guard_and_linesearch.py
+import torch
+from usd.utils.checks import assert_finite
+
+def test_assert_finite_raises():
+    x = torch.tensor([1.0, float("nan")])
+    try:
+        assert_finite(x, "x")
+        assert False, "should have raised"
+    except FloatingPointError:
+        pass
*** End Patch
```

```diff
*** Begin Patch
*** Add File: tests/test_bc_and_similarity.py
+import torch
+from usd.physics.bc import enforce_bc
+from usd.physics.self_similar import forward_transform, inverse_transform, Similarity
+
+def test_dirichlet_bc_overwrite():
+    u = torch.zeros(1,1,4,4)
+    bc = torch.ones(1,1,4,4)
+    out = enforce_bc(u, bc, "dirichlet")
+    assert out.sum().item() == 16.0
+
+def test_similarity_roundtrip():
+    x = torch.tensor([1.0, 2.0])
+    t = torch.tensor(0.5)
+    sim = Similarity(alpha=0.3, beta=0.0)
+    xp = forward_transform(x, t, sim)
+    xr = inverse_transform(xp, t, sim)
+    assert torch.allclose(x, xr, atol=1e-12)
*** End Patch
```

---

# 필수 패치 6 — 의존성 핀 고정(재현성)

```diff
*** Begin Patch
*** Update File: requirements.txt
@@
-torch
+torch==2.4.0
+torchvision==0.19.0
+torchaudio==2.4.0
+numpy==2.1.1
+pyyaml==6.0.2
+pydantic==2.9.2
+tensorboard==2.17.1
*** End Patch
```

> **주의:** CUDA 버전에 맞는 torch 빌드가 필요합니다. README에 “torch 설치 가이드(프리릴리즈/쿠다 wheel 링크)”를 추가하세요.

---

# 필수 패치 7 — README: 정밀도/결정성/설정 검증 섹션 추가(톤다운)

```diff
*** Begin Patch
*** Update File: README.md
@@
+## Precision & Determinism
+- 기본 정밀도는 `float64`, AMP/TF32는 **비활성화**됩니다(수치 안정성 우선).
+- 가능한 연산은 결정적 알고리즘을 사용합니다(`torch.use_deterministic_algorithms(True)`).
+- CUDA/드라이버에 따라 일부 커널이 비결정적일 수 있으며, 이 경우 경고가 출력됩니다.
+
+## Config Validation
+- 모든 설정은 **Pydantic 스키마**로 검증됩니다. 잘못된 키/값은 시작 단계에서 실패합니다.
+
+## Safety
+- 학습 단계마다 **NaN/Inf 가드**가 활성화됩니다.
+- Gauss–Newton 업데이트는 **LM-댐핑 + 백트래킹 라인서치**로 잔차 악화를 완화합니다.
*** End Patch
```

---

## 왜 “필수”인가?

* **정밀도/결정성**: 이 주제는 “극저오차/불안정 특이해” 탐색이므로 AMP/TF32는 금물이고, float64·결정성이 기본값이어야 합니다.
* **설정 검증**: 잘못된 config가 “된다”가 아니라 “일찍 죽는다”가 재현성에 유리합니다.
* **NaN/Inf 가드 + 라인서치/댐핑**: GN 업데이트의 폭주/잔차 악화를 즉시 억제해 학습을 **망가뜨리지 않습니다**.
* **경계·좌표 일관성**: 자기유사 좌표·경계조건의 단위 불일치를 방치하면 고정밀 논의가 무의미해집니다.
* **핀 고정**: 버전 부동은 재현성의 최대 적. 최소한의 핀 고정이 필요합니다.

---

필요하시면 위 패치를 **PR 두 개**(① 수치/설정 안정화, ② 물리/경계·테스트)로 쪼개서 제목/본문까지 포함해 드릴게요.
